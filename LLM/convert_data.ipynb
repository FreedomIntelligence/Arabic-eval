{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "358d544d-c469-4135-8094-5cc09158e179",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yufei/anaconda3/envs/causal/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datasets\n",
    "import jsonlines\n",
    "import json\n",
    "import re\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a3c7e0-8348-4af3-8a0f-80ea830a2306",
   "metadata": {},
   "source": [
    "# MMCU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1ce33cbd-465c-4a9c-a199-b49b9c922cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "choices = [\"A\", \"B\", \"C\", \"D\"]\n",
    "avail_choices = list(set([''.join(sorted(set(x))) for x in product(choices, repeat=4)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "02e89a88-d111-453b-85ee-1f1b29d9983f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['医疗', '心理', '教育_化学', '教育_历史', '教育_地理', '教育_政治', '教育_数学', '教育_物理', '教育_生物', '教育_语文', '法律']\n"
     ]
    }
   ],
   "source": [
    "subjects = sorted([f.split(\".xlsx\")[0] for f in os.listdir(os.path.join('benchmark_eval/benchmarks/MMCU/origin', \"test\")) if \".xlsx\" in f])\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "82403754-8eee-4994-870a-1c7103480719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def standarize_question(question):\n",
    "    question = question.strip()\n",
    "    question = re.sub(r'\\u3000', r'', question).strip().lstrip('、．.')\n",
    "    return question\n",
    "\n",
    "def standardize_option(option):\n",
    "    option = str(option).strip()\n",
    "    option = re.sub(r'\\u3000', r'', option)\n",
    "    option = re.sub(r'^[ABCDＡＢＣＤ][、．\\.]?\\s?', r'', option)\n",
    "    option = option.strip().lstrip('、．.')\n",
    "    return option\n",
    "    # return option.replace(\" ．\", \"\").replace(\"A、\", \"\").replace(\"B、\", \"\").replace(\"C、\", \"\").replace(\"D、\", \"\").replace(\"A.\", \"\").replace(\"B.\", \"\").replace(\"C.\", \"\").replace(\"D.\", \"\").replace(\"A\", \"\").replace(\"B\", \"\").replace(\"C\", \"\").replace(\"D\", \"\").replace(\"Ａ、\", \"\").replace(\"Ｂ、\", \"\").replace(\"Ｃ、\", \"\").replace(\"Ｄ、\", \"\")\n",
    "\n",
    "def standardize_answer(answer):\n",
    "    answer = answer.strip()\n",
    "    answer = answer.replace(\" \", \"\").replace(\",\", \"\")\n",
    "    answer = answer.replace(\"Ａ\", \"A\").replace(\"Ｂ\", \"B\").replace(\"Ｃ\", \"C\").replace(\"Ｄ\", \"D\")\n",
    "    return ''.join(sorted(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b7b062a2-6c84-4da4-a3f1-63f7b93c22eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 5\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 449.65ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dev\n",
    "\n",
    "## 医疗\n",
    "\n",
    "df = pd.read_excel(os.path.join('benchmark_eval/benchmarks/MMCU/origin', \"dev\", \"医疗\" + \".xlsx\"), header=0)\n",
    "\n",
    "data_list = []\n",
    "n = 0\n",
    "for i in range(df.shape[0]):\n",
    "    prompt = standarize_question(df.iloc[i,0])\n",
    "    k = df.shape[1] - 2\n",
    "    for j in range(k):\n",
    "        prompt += \"\\n{}. {}\".format(choices[j], standardize_option(df.iloc[i, j+1]))\n",
    "    answer = standardize_answer(df.iloc[i, k + 1])\n",
    "    if answer not in avail_choices:\n",
    "        n += 1\n",
    "        continue\n",
    "    \n",
    "    data_list.append({\n",
    "        'query_id': i,\n",
    "        'query': prompt,\n",
    "        'answer': answer,\n",
    "    })\n",
    "\n",
    "dataset = datasets.Dataset.from_list(data_list)\n",
    "print(dataset)\n",
    "dataset.to_json(os.path.join('benchmark_eval/benchmarks/MMCU/converted', \"dev\", \"医疗.jsonl\"), force_ascii=False)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8621199a-83d7-435a-8fad-f9f48140fba9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 5\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 417.55ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 5\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 487.26ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 5\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 490.28ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 5\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 543.37ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 5\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 533.42ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 5\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 495.55ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 5\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 554.14ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 5\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 562.84ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 5\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 540.43ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 5\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 484.22ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 非医疗\n",
    "\n",
    "n = 0\n",
    "for subject in subjects:\n",
    "    if subject != \"医疗\":\n",
    "        df = pd.read_excel(os.path.join('benchmark_eval/benchmarks/MMCU/origin', \"dev\", subject + \".xlsx\"), header=0)\n",
    "        \n",
    "        data_list = []\n",
    "        for i in range(df.shape[0]):\n",
    "            prompt = standarize_question(df.iloc[i,0])\n",
    "            k = df.shape[1] - 2\n",
    "            for j in range(k):\n",
    "                prompt += \"\\n{}. {}\".format(choices[j], standardize_option(df.iloc[i, j+1]))\n",
    "            answer = standardize_answer(df.iloc[i, k + 1])\n",
    "            if answer not in avail_choices:\n",
    "                n += 1\n",
    "                continue\n",
    "\n",
    "            data_list.append({\n",
    "                'query_id': i,\n",
    "                'query': prompt,\n",
    "                'answer': answer,\n",
    "            })\n",
    "\n",
    "        dataset = datasets.Dataset.from_list(data_list)\n",
    "        print(dataset)\n",
    "        dataset.to_json(os.path.join('benchmark_eval/benchmarks/MMCU/converted', \"dev\", f\"{subject}.jsonl\"), force_ascii=False)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd53b6db-e155-4a2f-bb73-92d89eaf35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fe2d402f-162a-4c08-af16-f380d798d892",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 299\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 268.16ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 200\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 373.66ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 690\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 199.87ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 176\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 431.02ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 101\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 429.61ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 339\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 294.28ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 219\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 375.90ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 22\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 714.90ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 20\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 556.05ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 100\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 524.48ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 163\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 448.78ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 213\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 360.80ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 51\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 514.76ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 154\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 420.78ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 72\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 506.37ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "## 医疗\n",
    "f = pd.ExcelFile(os.path.join('benchmark_eval/benchmarks/MMCU/origin', \"test\", \"医疗\" + \".xlsx\"))\n",
    "sheet_list = f.sheet_names\n",
    "n = 0\n",
    "for sheet in sheet_list:\n",
    "    df = pd.read_excel(os.path.join('benchmark_eval/benchmarks/MMCU/origin', \"test\", \"医疗\" + \".xlsx\"), header=0, sheet_name=sheet)\n",
    "    \n",
    "    data_list = []\n",
    "    for i in range(df.shape[0]):\n",
    "        prompt = standarize_question(df.iloc[i,0])\n",
    "        k = df.shape[1] - 2\n",
    "        for j in range(k):\n",
    "            prompt += \"\\n{}. {}\".format(choices[j], standardize_option(df.iloc[i, j+1]))\n",
    "        answer = standardize_answer(df.iloc[i, k + 1])\n",
    "        if answer not in avail_choices:\n",
    "            n += 1\n",
    "            print(answer)\n",
    "            continue\n",
    "\n",
    "        data_list.append({\n",
    "            'query_id': i,\n",
    "            'query': prompt,\n",
    "            'answer': answer,\n",
    "        })\n",
    "\n",
    "    dataset = datasets.Dataset.from_list(data_list)\n",
    "    print(dataset)\n",
    "    name = re.match(r'(.+?)\\d+题', sheet).group(1)\n",
    "    dataset.to_json(os.path.join('benchmark_eval/benchmarks/MMCU/converted', \"test\", \"医疗\", f\"{name}.jsonl\"), force_ascii=False)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "caf5d202-d0bf-408a-a71c-2f23b11b4373",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 2000\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 147.33ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 50\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 528.38ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 864\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 108.94ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 705\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 125.36ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 714\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 81.42ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 335\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 296.40ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 168\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 388.33ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 237\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 397.94ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 258\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 233.61ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query_id', 'query', 'answer'],\n",
      "    num_rows: 3695\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 83.76ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 非医疗\n",
    "n = 0\n",
    "for subject in subjects:\n",
    "    if subject != \"医疗\":\n",
    "        df = pd.read_excel(os.path.join('benchmark_eval/benchmarks/MMCU/origin', \"test\", subject + \".xlsx\"), header=0)\n",
    "        \n",
    "        data_list = []\n",
    "        for i in range(df.shape[0]):\n",
    "            prompt = standarize_question(df.iloc[i,0])\n",
    "            k = df.shape[1] - 2\n",
    "            for j in range(k):\n",
    "                prompt += \"\\n{}. {}\".format(choices[j], standardize_option(df.iloc[i, j+1]))\n",
    "            answer = standardize_answer(df.iloc[i, k + 1])\n",
    "            if answer not in avail_choices:\n",
    "                n += 1\n",
    "                print(subject, i, df.iloc[i,0], answer)\n",
    "                continue\n",
    "\n",
    "            data_list.append({\n",
    "                'query_id': i,\n",
    "                'query': prompt,\n",
    "                'answer': answer,\n",
    "            })\n",
    "\n",
    "        dataset = datasets.Dataset.from_list(data_list)\n",
    "        print(dataset)\n",
    "        dataset.to_json(os.path.join('benchmark_eval/benchmarks/MMCU/converted', \"test\", f\"{subject}.jsonl\"), force_ascii=False)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c361d60-b4f5-4ccb-b2d2-461b14ba00b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4eba3d-2541-46d3-b614-5713e5e26719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "29645f5f-0bc1-4d5b-b7a9-bc00f12894f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-76813faa63d57244/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7084.97it/s]\n",
      "Extracting data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1093.12it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-76813faa63d57244/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-8fe914debfb5c7f6/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6955.73it/s]\n",
      "Extracting data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1029.53it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-8fe914debfb5c7f6/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-4eba8324a9f1b5b2/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7013.89it/s]\n",
      "Extracting data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1381.52it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-4eba8324a9f1b5b2/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-04d0bb2efaa6c8d3/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1922.23it/s]\n",
      "Extracting data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1218.92it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-04d0bb2efaa6c8d3/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-6ad409941b7dd5f4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7037.42it/s]\n",
      "Extracting data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1411.75it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-6ad409941b7dd5f4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-755c3b9ed60201a0/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7073.03it/s]\n",
      "Extracting data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1088.30it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-755c3b9ed60201a0/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-970a1c26994c8dbf/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6864.65it/s]\n",
      "Extracting data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1097.70it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-970a1c26994c8dbf/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-4d4ac8ebca1cf260/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5511.57it/s]\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 671.52it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-4d4ac8ebca1cf260/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-00a0adec3b39960e/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7194.35it/s]\n",
      "Extracting data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1080.17it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-00a0adec3b39960e/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-a8d48c02fcac37de/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7084.97it/s]\n",
      "Extracting data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1166.70it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-a8d48c02fcac37de/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-99830a53541bb1b2/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7049.25it/s]\n",
      "Extracting data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1125.38it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-99830a53541bb1b2/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# few_shot_prompting\n",
    "\n",
    "for subject in subjects:\n",
    "    dataset = datasets.load_dataset(\"json\", data_files=os.path.join(f'/workspace2/yufei/LLM-eval-pipeline/benchmark_eval/benchmarks/MMCU/converted/dev/{subject}.jsonl'), split='train')\n",
    "    prompt = \"\"\n",
    "    for i in range(len(dataset)):\n",
    "        prompt += dataset[i]['query']\n",
    "        prompt += \"\\n正确答案的序号是：\" \n",
    "        prompt += \" {}\\n\\n\".format(dataset[i]['answer'])\n",
    "    prompt += '{question}\\n正确答案的序号是：'\n",
    "    with open(f'/workspace2/yufei/LLM-eval-pipeline/benchmark_eval/benchmarks/MMCU/converted/few_shot_prompt/{subject}', 'w') as f:\n",
    "        f.write(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9467048-67af-4277-ac5e-2eaccfd4d637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d094145f-10b3-42f7-83f8-257171857eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c4d117-967a-43af-ba71-9c84de66b021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "314b91aa-5226-4e34-958d-d352d8ed68d9",
   "metadata": {},
   "source": [
    "# GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b63ce6c-53f3-44aa-8d86-381485e6cbc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 1319\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "with jsonlines.open('/workspace2/yufei/LLM-eval-pipeline/benchmark_eval/benchmarks/GSM8K/origin/test.jsonl') as reader:\n",
    "    for obj in reader:\n",
    "        data.append(obj)\n",
    "        \n",
    "dataset = datasets.Dataset.from_list(data)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9e817-fc91-4686-a4a3-ee6ea3620054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06f3287e-15d0-4ffe-82cc-93aa3d453c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    y = ''.join(x.split(','))\n",
    "    if '.' in y:\n",
    "        y = y.rstrip('0')\n",
    "        if y[-1] == '.':\n",
    "            y = y[:-1]\n",
    "    if y[0] == '.':\n",
    "        y = '0' + y\n",
    "    if y[-1] == '%':\n",
    "        y = str(eval(y[:-1]) / 100)\n",
    "    return y\n",
    "\n",
    "def process(example, idx):\n",
    "    return {\n",
    "        \"query_id\": idx, \n",
    "        'query': example['question'],\n",
    "        'ground': eval(standardize(example['answer'].split('#### ')[-1])),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17675fd1-513f-4071-882d-96aca17f2412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                    \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['query_id', 'query', 'ground'],\n",
       "    num_rows: 1319\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = dataset.map(process, with_indices=True, remove_columns=dataset.column_names)\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c062ea0-36eb-4ca8-a8c2-d0f3b561025f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['query_id', 'query', 'answer'],\n",
       "    num_rows: 1319\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = new_dataset.rename_column(\"ground\", \"answer\")\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a02f8a5-cda4-4b11-b3a6-ced84028e9c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 169.28ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "370333"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.to_json(os.path.join('benchmark_eval/benchmarks/GSM8K/converted', \"test.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3065742-87e9-420a-b87c-3338de0c3f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "569ef7b9-0fa9-4dd4-9239-776591d83019",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 21 trees now and there are 15 trees in the beginning, so the workers plant 21 - 15 = 6 trees. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are 3 cars in the beginning, 2 more arrive, so now there should be 3 + 2 = 5 cars. The answer is 5.\n",
      "\n",
      "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
      "A: Leah had 32 chocolates and her sister had 42, in total they have 32 + 42 = 74 chocolates. After they ate 35, now there are 74 - 35 = 39 chocolates. The answer is 39.\n",
      "\n",
      "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\n",
      "A: Jason started with 20 lollipops, but now he only has 12, so he gave Denny 20 - 12 = 8 lollipops. The answer is 8.\n",
      "\n",
      "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\n",
      "A: Shawn got 2 toys each from his mom and dad, so he got 2 * 2 = 4 more, now he will have 5 + 4 = 9 toys. The answer is 9.\n",
      "\n",
      "Q: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\n",
      "A: 5 computers were installed from monday to thursday, so in total 5 * 4 = 20 computers are installed. 9 computers are there in the beginning, so now there are 20 + 9 = 29 computers. The answer is 29.\n",
      "\n",
      "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\n",
      "A: Michael started with 58 golf balls and lost 23, so he has 58 - 23 = 35. After he lost 2 more, he has 35 - 2 = 33 balls now. The answer is 33.\n",
      "\n",
      "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
      "A: 5 bagels for $3 each should cost 5 * 3 = 15 dollars. Olivia had $23 in the beginning, so now she has 23 - 15 = 8 dollars left. The answer is 8.\n",
      "\n",
      "Q: {question}\n",
      "A: \n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = \"\"\"\n",
    "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
    "A: There are 21 trees now and there are 15 trees in the beginning, so the workers plant 21 - 15 = 6 trees. The answer is 6.\n",
    "\n",
    "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
    "A: There are 3 cars in the beginning, 2 more arrive, so now there should be 3 + 2 = 5 cars. The answer is 5.\n",
    "\n",
    "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
    "A: Leah had 32 chocolates and her sister had 42, in total they have 32 + 42 = 74 chocolates. After they ate 35, now there are 74 - 35 = 39 chocolates. The answer is 39.\n",
    "\n",
    "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\n",
    "A: Jason started with 20 lollipops, but now he only has 12, so he gave Denny 20 - 12 = 8 lollipops. The answer is 8.\n",
    "\n",
    "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\n",
    "A: Shawn got 2 toys each from his mom and dad, so he got 2 * 2 = 4 more, now he will have 5 + 4 = 9 toys. The answer is 9.\n",
    "\n",
    "Q: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\n",
    "A: 5 computers were installed from monday to thursday, so in total 5 * 4 = 20 computers are installed. 9 computers are there in the beginning, so now there are 20 + 9 = 29 computers. The answer is 29.\n",
    "\n",
    "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\n",
    "A: Michael started with 58 golf balls and lost 23, so he has 58 - 23 = 35. After he lost 2 more, he has 35 - 2 = 33 balls now. The answer is 33.\n",
    "\n",
    "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
    "A: 5 bagels for $3 each should cost 5 * 3 = 15 dollars. Olivia had $23 in the beginning, so now she has 23 - 15 = 8 dollars left. The answer is 8.\n",
    "\n",
    "Q: {question}\n",
    "A: \n",
    "\"\"\".strip('\\n')\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64af7dd1-6f05-4f91-90bc-723e581eb640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('benchmark_eval/benchmarks/GSM8K/converted', \"few_shot_prompt\"), 'w') as f:\n",
    "    f.write(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2510e-f2a3-43a5-b7a5-135e83476c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661aae74-b280-4e31-9faa-9c66cbc95fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efbbb96d-ccaf-4752-a4d3-71bcad170b0e",
   "metadata": {},
   "source": [
    "# KUAKE-QIC_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e40b946-65a6-40dc-a15a-6a46452e6ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-36fe121c173ad2c4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1184.50it/s]\n",
      "Extracting data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1233.26it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-36fe121c173ad2c4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n",
      "Dataset({\n",
      "    features: ['id', 'query', 'label'],\n",
      "    num_rows: 1994\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "path = \"/workspace2/yufei/LLM-eval-pipeline/generation/data/KUAKE-QIC/KUAKE-QIC_test.json\"\n",
    "dataset = datasets.load_dataset(\"json\", data_files=path, split=\"train\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad42cc99-33a4-4544-b550-e80e93309db2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'label', 'instruction', 'input'],\n",
       "    num_rows: 1994\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = dataset.add_column(\"instruction\", dataset['query']).add_column(\"input\", [\"\"]*len(dataset))\n",
    "new_dataset = new_dataset.remove_columns(['query'])\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef1857cb-c1be-42b4-bd93-86b87cd83da7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 187.95ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "164633"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.to_json(\"/workspace2/yufei/LLM-eval-pipeline/generation/data/KUAKE-QIC/test.jsonl\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff0885-7fc0-4c25-956f-7d5f5e9d8a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3586f960-10b2-415b-ad2a-487d2f6f3f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9a5128c-dfb2-4ce8-bc5f-2b258ac14e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-8952c53014e2b982/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1603.94it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 94.97it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-8952c53014e2b982/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-c90cd89c23788a92/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2568.47it/s]\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 131.67it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-c90cd89c23788a92/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-0da3649a6d09289c/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2049.00it/s]\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 266.71it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-0da3649a6d09289c/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-dfca6336a976cc10/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 332.51it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 47.85it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-dfca6336a976cc10/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-2c0c5993eb393c68/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1903.91it/s]\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 101.37it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-2c0c5993eb393c68/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-cfc2d6d7a03e54c6/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1762.31it/s]\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 171.99it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-cfc2d6d7a03e54c6/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-823d379862c3b253/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1336.62it/s]\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 159.44it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-823d379862c3b253/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-8dccb9355fb9a5ef/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1838.80it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 95.47it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-8dccb9355fb9a5ef/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-2a592fac69a250eb/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2107.69it/s]\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 248.37it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-2a592fac69a250eb/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/yufei/.cache/huggingface/datasets/json/default-4678948a604e5528/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2775.85it/s]\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 136.96it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yufei/.cache/huggingface/datasets/json/default-4678948a604e5528/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'instruction', 'input', 'output', 'score'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['功效作用.jsonl', '医疗费用.jsonl', '后果表述.jsonl', '就医建议.jsonl', '指标解读.jsonl', '治疗方案.jsonl', '注意事项.jsonl', '疾病表述.jsonl', '病因分析.jsonl', '病情诊断.jsonl']\n",
    "\n",
    "data_list = []\n",
    "for category in categories:\n",
    "    path = f\"/home/yufei/LLM-eval-pipeline/generation/data/KUAKE-QIC/{category}\"\n",
    "    dataset = datasets.load_dataset(\"json\", data_files=path, split=\"train\")\n",
    "    data_list.append(dataset)\n",
    "    \n",
    "dataset = datasets.concatenate_datasets(data_list)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d18636b7-5c56-475f-8c45-cc45955d7591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                    \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'label', 'query'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = dataset.map(lambda example: {'id': example['id'], 'label': example['instruction'], 'query': example['input']}, remove_columns=dataset.column_names)\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59ece705-35e0-4e88-970a-b71517b0cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 140.11ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8971"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.to_json(\"/home/yufei/LLM-eval-pipeline/generation/data/KUAKE-QIC/test_100.jsonl\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec3dc7a-37cf-4feb-a4c8-8bc7eeb8c8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc8607-9010-4c73-a3be-5587c1d36dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f45d69-ab69-4ac2-a45d-daa7b0a2a786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09a890e6-2337-4864-a1c1-6d0f90f23fa8",
   "metadata": {},
   "source": [
    "# real_qa_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7236edf5-4b83-4971-b1ea-7dc132c57c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/yufei/.cache/huggingface/datasets/json/default-1ed73b1af6a55d9a/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"json\", data_files=\"/home/chenjunying/huatuo/instruction/real_qa_test.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e06347ca-cb4a-4537-b143-06f448a08232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'source', 'answer'],\n",
       "    num_rows: 164858\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15bb4aa9-6d02-4a60-b170-36bda924d6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '我儿子从小就免疫力特别的差，经常的会上火感冒，只要是受凉感冒就会嗓子肿痛发炎，严重时会化脓，特别的影响孩子的学习，医生说可以做扁桃体手术不影响孩子的成长。低温等离子消融技术治扁桃体手术后注意事项有哪些？',\n",
       " 'source': 1,\n",
       " 'answer': '扁桃体炎会诱发局部并发症有急性中耳炎、鼻炎、鼻窦炎、咽炎、颈淋巴结炎、扁桃体周围脓肿等。扁桃体炎会诱发全身并发症常见的有风湿并急性肾小球肾炎、败血症、关节炎、皮肤疾患（如银屑病）、心肌炎、支气管哮喘等。 要想避免扁桃体炎诱发上述疾病，就一定要及时进行治疗，并做好日常防护工作。先进的低温等离子消融技术，也广泛应用在治疗轻度扁条体炎方面。 低温等离子消融技术是利用低温等离子射频的能量，以较低的温度（40-70度左右）来进行组织的切除，从而减轻组织的损伤，并能大大减轻病人的痛苦和缩短康复的周期，且效果较好。 术后需要观察有无出血情况，所以一般在术后四小时内禁食，禁止作吞咽动作，嘴里的分泌物劝导病人将分泌物吐出来；如果没有出血的话，可以适当地进小量冷饮；四小时后可以进冷流汁，八小时后可以进半流汁；术后刚进食时都会有疼痛感，进温流汁感觉会好一些。 要注意休息。二周内不要做较重的体力活动，也不要用力屏气，以防血管破裂引起出血以上是对低温等离子消融技术治扁桃体手术后注意事项这个问题的建议，希望对您有帮助，祝您降！\\n'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6449a35d-e3db-4957-b2b1-cb67304c0b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 6, 7}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5a4c166-b418-461e-9bf6-8ecd03bae034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "n_all = 500\n",
    "n_divide3 = n_all // 3\n",
    "\n",
    "dataset = dataset.filter(lambda example: len(example[\"question\"]) != 0)\n",
    "dataset1 = dataset.filter(lambda example: example[\"source\"] == 1).select(range(n_divide3))\n",
    "dataset2 = dataset.filter(lambda example: example[\"source\"] == 6).select(range(n_divide3))\n",
    "dataset3 = dataset.filter(lambda example: example[\"source\"] == 7).select(range(n_all-2*n_divide3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8aea9265-06b4-4b00-b376-260a45e2f843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'source', 'answer'],\n",
      "    num_rows: 166\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'source', 'answer'],\n",
      "    num_rows: 166\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'source', 'answer'],\n",
      "    num_rows: 168\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset1)\n",
    "print(dataset2)\n",
    "print(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bcc0426-ea3c-4cff-9d29-c025488c53d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'source', 'answer'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataset = datasets.concatenate_datasets([dataset1,dataset2,dataset3])\n",
    "all_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c083ec4-b223-4c87-b47e-3b6b16539794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                    \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'query', 'reference_answer'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataset = all_dataset.map(lambda example, idx: {\"id\": idx, \"query\": example[\"question\"], \"reference_answer\": example[\"answer\"]}, with_indices=True, remove_columns=all_dataset.column_names)\n",
    "all_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13827ae4-6683-4de4-9f6b-a3615c8a4029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.07ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "490102"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataset.to_json(\"/home/yufei/LLM-eval-pipeline/generation/data/real_qa_test/test_500.jsonl\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dcd21d-38e5-4f93-9aaf-8d781fe5493a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34122f73-2246-4a82-8e35-37162c8ffc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a3265-3a39-4c33-a1c7-1f7c57049ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "163abe9d-4bbb-4532-a148-6de282114265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'query', 'reference_answer'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1 = all_dataset.select(range(33))\n",
    "dataset2 = all_dataset.select(range(200, 233))\n",
    "dataset3 = all_dataset.select(range(400, 434))\n",
    "small_dataset = datasets.concatenate_datasets([dataset1,dataset2,dataset3])\n",
    "small_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab8bf996-4fd4-46c2-9016-ea9a6c871da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 152.08ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104495"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset.to_json(\"/home/yufei/LLM-eval-pipeline/generation/data/real_qa_test/test_100.jsonl\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6507b23-8ced-4c9a-aae8-274b084f0b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab56d9f-d4ca-4f06-8767-ac8fc78a9a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c996c-bc47-4341-b6d2-4b0da3746571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207c7a0b-465a-4ed8-b57f-52e56538bc56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2367232-e998-4bf8-af64-62f74bff2e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "causal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
