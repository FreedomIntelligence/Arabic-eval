{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eae281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5ae994",
   "metadata": {},
   "source": [
    "# SFT Zero-shot Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e4c5d0",
   "metadata": {},
   "source": [
    "## MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5beeb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_score_for_categories(data):\n",
    "    results = {}\n",
    "    for category, subcategories in data.items():\n",
    "        for subcategory, values in subcategories.items():\n",
    "            if \"average\" in values:\n",
    "                results[category] = values[\"average\"][\"Accuracy\"]\n",
    "                break\n",
    "    score = np.mean([average for category, average in results.items()])\n",
    "    for category, average in results.items():\n",
    "        print(f\"{category}: {average:.2%}\")\n",
    "    print(f'mean of all category: {score:.2%}')\n",
    "    print(f'{score*100:.2f}' + ''.join([f' {ave*100 :.2f}' for ave in results.values()]))\n",
    "    return results,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13e49c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEM: 30.83%\n",
      "humanities: 25.15%\n",
      "social sciences: 49.11%\n",
      "other (business, health, misc.): 32.70%\n",
      "mean of all category: 34.45%\n",
      "34.45 30.83 25.15 49.11 32.70\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = json.load(open(os.path.join('/home/yufei/arabic/LLM-eval-pipeline/benchmark_eval/results/MMLUArabic/gpt-3.5-turbo/zero_shot/metrics.json')))\n",
    "results,score = get_average_score_for_categories(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b588e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEM: 23.88%\n",
      "humanities: 28.93%\n",
      "social sciences: 33.94%\n",
      "other (business, health, misc.): 29.72%\n",
      "mean of all category: 29.12%\n",
      "29.12 23.88 28.93 33.94 29.72\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f749cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEM: 27.93%\n",
      "humanities: 27.50%\n",
      "social sciences: 32.05%\n",
      "other (business, health, misc.): 33.08%\n",
      "mean of all category: 30.14%\n",
      "30.14 27.93 27.50 32.05 33.08\n"
     ]
    }
   ],
   "source": [
    "data = json.load(open(os.path.join('benchmark_eval/results/MMLUArabic/bloomz-ace-v5.0/zero_shot/metrics.json')))\n",
    "results,score = get_average_score_for_categories(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7486da",
   "metadata": {},
   "source": [
    "## Exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "911ebd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Islamic Studies': {'Accuracy': 0.3835616438356164},\n",
       " 'Science': {'Accuracy': 0.3826086956521739},\n",
       " 'Social': {'Accuracy': 0.34558823529411764},\n",
       " 'Biology': {'Accuracy': 0.22857142857142856},\n",
       " 'Physics': {'Accuracy': 0.35714285714285715},\n",
       " 'average': {'Accuracy': 0.3394945720992387},\n",
       " 'overall': {'Accuracy': 0.35195530726256985}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.load(open(os.path.join('benchmark_eval/results/EXAMS_Arabic/llama-pretrained-v5.2/zero_shot/metrics.json')))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95f7bbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Islamic Studies': {'Accuracy': 0.2602739726027397},\n",
       " 'Science': {'Accuracy': 0.3652173913043478},\n",
       " 'Social': {'Accuracy': 0.2977941176470588},\n",
       " 'Biology': {'Accuracy': 0.37142857142857144},\n",
       " 'Physics': {'Accuracy': 0.40476190476190477},\n",
       " 'average': {'Accuracy': 0.33989519154892456},\n",
       " 'overall': {'Accuracy': 0.3202979515828678}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.load(open(os.path.join('benchmark_eval/results/EXAMS_Arabic/bloomz-ace-v5.0/zero_shot/metrics.json')))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63ec106",
   "metadata": {},
   "source": [
    "## Addition Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42b62117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'easy': {'Arabic Funeral': {'Accuracy': 0.6},\n",
       "  'Sudan': {'Accuracy': 0.6444444444444445},\n",
       "  'Arabic Physics and Chemistry': {'Accuracy': 0.4666666666666667},\n",
       "  'Algeria': {'Accuracy': 0.5076923076923077},\n",
       "  'InfluenceFromAncientEgypt': {'Accuracy': 0.4},\n",
       "  'Arabic Ceremony': {'Accuracy': 0.4864864864864865},\n",
       "  'Arabic Astronomy': {'Accuracy': 0.5333333333333333},\n",
       "  'Arabic Calligraphy': {'Accuracy': 0.5215686274509804},\n",
       "  'daily life': {'Accuracy': 0.8130563798219584},\n",
       "  'Saudi Arabia': {'Accuracy': 0.7076923076923077},\n",
       "  'Arabic Language Origin': {'Accuracy': 0.5473684210526316},\n",
       "  'Arabic Ornament': {'Accuracy': 0.5282051282051282},\n",
       "  'Islamic law system': {'Accuracy': 0.5794871794871795},\n",
       "  'Kuwait': {'Accuracy': 0.7333333333333333},\n",
       "  'InfluenceFromChina': {'Accuracy': 0.7333333333333333},\n",
       "  'Arabic Literature': {'Accuracy': 0.5379310344827586},\n",
       "  'computer and phone': {'Accuracy': 0.559322033898305},\n",
       "  'Tunisia': {'Accuracy': 0.6888888888888889},\n",
       "  'Arabic Geography': {'Accuracy': 0.3931034482758621},\n",
       "  'Arabic Music': {'Accuracy': 0.7769784172661871},\n",
       "  'Arabic Medicine': {'Accuracy': 0.5379310344827586},\n",
       "  'Arabic Philosophy': {'Accuracy': 0.4206896551724138},\n",
       "  'Yemen': {'Accuracy': 0.8},\n",
       "  'Jordan': {'Accuracy': 0.6888888888888889},\n",
       "  'Mesopotamia civilization': {'Accuracy': 0.4774193548387097},\n",
       "  'Islam Education': {'Accuracy': 0.5487179487179488},\n",
       "  'Arabic Wedding': {'Accuracy': 0.5897435897435898},\n",
       "  'InfluenceFromRome': {'Accuracy': 0.4256410256410256},\n",
       "  'Egypt modern': {'Accuracy': 0.6842105263157895},\n",
       "  'Ancient Egypt': {'Accuracy': 0.9492063492063492},\n",
       "  'Comoros': {'Accuracy': 0.6222222222222222},\n",
       "  'InfluenceFromGreece': {'Accuracy': 0.37435897435897436},\n",
       "  'Qatar': {'Accuracy': 0.6222222222222222},\n",
       "  'InfluenceFromPersia': {'Accuracy': 0.3314285714285714},\n",
       "  'Lebanon': {'Accuracy': 0.8222222222222222},\n",
       "  'Arabic Math': {'Accuracy': 0.6974358974358974},\n",
       "  'Arabic History': {'Accuracy': 0.6974358974358974},\n",
       "  'InfluenceFromIslam': {'Accuracy': 0.7310344827586207},\n",
       "  'Libya': {'Accuracy': 0.5555555555555556},\n",
       "  'Syria': {'Accuracy': 0.6666666666666666},\n",
       "  'Oman': {'Accuracy': 0.8222222222222222},\n",
       "  'Arabic Culture': {'Accuracy': 0.7692307692307693},\n",
       "  'Arabic Art': {'Accuracy': 0.6358974358974359},\n",
       "  'United Arab Emirates': {'Accuracy': 0.7647058823529411},\n",
       "  'Islam branches and schools': {'Accuracy': 0.5657142857142857},\n",
       "  'InfluenceFromByzantium': {'Accuracy': 0.296551724137931},\n",
       "  'Arab Empire': {'Accuracy': 0.690566037735849},\n",
       "  'Arabic Food': {'Accuracy': 0.558974358974359},\n",
       "  'Mauritania': {'Accuracy': 0.5777777777777777},\n",
       "  'entertainment': {'Accuracy': 0.7864406779661017},\n",
       "  'communication': {'Accuracy': 0.5961538461538461},\n",
       "  'Palestine': {'Accuracy': 0.7529411764705882},\n",
       "  'Bahrain': {'Accuracy': 0.6888888888888889},\n",
       "  'Somalia': {'Accuracy': 0.6444444444444445},\n",
       "  'Iraq': {'Accuracy': 0.5411764705882353},\n",
       "  'Arabic Clothing': {'Accuracy': 0.48717948717948717},\n",
       "  'Arabic Architecture': {'Accuracy': 0.5435897435897435},\n",
       "  'Morocco': {'Accuracy': 0.7777777777777778},\n",
       "  'average': {'Accuracy': 0.6121061355901569},\n",
       "  'overall': {'Accuracy': 0.6021814006888634}},\n",
       " 'middle': {'talks': {'Accuracy': 0.3333333333333333},\n",
       "  'traditional festival': {'Accuracy': 0.5714285714285714},\n",
       "  'life': {'Accuracy': 0.6363636363636364},\n",
       "  'specialExpression': {'Accuracy': 0.72},\n",
       "  'Islam': {'Accuracy': 1.0},\n",
       "  'traveling': {'Accuracy': 0.5833333333333334},\n",
       "  'trade and bussness': {'Accuracy': 0.8},\n",
       "  'average': {'Accuracy': 0.6634941249226963},\n",
       "  'overall': {'Accuracy': 0.6666666666666666}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.load(open(os.path.join('benchmark_eval/results/ArabicCulture/llama-pretrained-v5.2/zero_shot/metrics.json')))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca6f1e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'easy': {'Arabic Funeral': {'Accuracy': 0.4105263157894737},\n",
       "  'Sudan': {'Accuracy': 0.35555555555555557},\n",
       "  'Arabic Physics and Chemistry': {'Accuracy': 0.5487179487179488},\n",
       "  'Algeria': {'Accuracy': 0.5230769230769231},\n",
       "  'InfluenceFromAncientEgypt': {'Accuracy': 0.6461538461538462},\n",
       "  'Arabic Ceremony': {'Accuracy': 0.5297297297297298},\n",
       "  'Arabic Astronomy': {'Accuracy': 0.4666666666666667},\n",
       "  'Arabic Calligraphy': {'Accuracy': 0.4745098039215686},\n",
       "  'daily life': {'Accuracy': 0.4065281899109792},\n",
       "  'Saudi Arabia': {'Accuracy': 0.3435897435897436},\n",
       "  'Arabic Language Origin': {'Accuracy': 0.6842105263157895},\n",
       "  'Arabic Ornament': {'Accuracy': 0.4717948717948718},\n",
       "  'Islamic law system': {'Accuracy': 0.5282051282051282},\n",
       "  'Kuwait': {'Accuracy': 0.28888888888888886},\n",
       "  'InfluenceFromChina': {'Accuracy': 0.26666666666666666},\n",
       "  'Arabic Literature': {'Accuracy': 0.5586206896551724},\n",
       "  'computer and phone': {'Accuracy': 0.46779661016949153},\n",
       "  'Tunisia': {'Accuracy': 0.3111111111111111},\n",
       "  'Arabic Geography': {'Accuracy': 0.6068965517241379},\n",
       "  'Arabic Music': {'Accuracy': 0.381294964028777},\n",
       "  'Arabic Medicine': {'Accuracy': 0.4827586206896552},\n",
       "  'Arabic Philosophy': {'Accuracy': 0.5862068965517241},\n",
       "  'Yemen': {'Accuracy': 0.2},\n",
       "  'Jordan': {'Accuracy': 0.3333333333333333},\n",
       "  'Mesopotamia civilization': {'Accuracy': 0.5225806451612903},\n",
       "  'Islam Education': {'Accuracy': 0.5230769230769231},\n",
       "  'Arabic Wedding': {'Accuracy': 0.558974358974359},\n",
       "  'InfluenceFromRome': {'Accuracy': 0.5794871794871795},\n",
       "  'Egypt modern': {'Accuracy': 0.3894736842105263},\n",
       "  'Ancient Egypt': {'Accuracy': 0.25396825396825395},\n",
       "  'Comoros': {'Accuracy': 0.37777777777777777},\n",
       "  'InfluenceFromGreece': {'Accuracy': 0.7538461538461538},\n",
       "  'Qatar': {'Accuracy': 0.4666666666666667},\n",
       "  'InfluenceFromPersia': {'Accuracy': 0.68},\n",
       "  'Lebanon': {'Accuracy': 0.2222222222222222},\n",
       "  'Arabic Math': {'Accuracy': 0.30256410256410254},\n",
       "  'Arabic History': {'Accuracy': 0.3230769230769231},\n",
       "  'InfluenceFromIslam': {'Accuracy': 0.4827586206896552},\n",
       "  'Libya': {'Accuracy': 0.4666666666666667},\n",
       "  'Syria': {'Accuracy': 0.3333333333333333},\n",
       "  'Oman': {'Accuracy': 0.26666666666666666},\n",
       "  'Arabic Culture': {'Accuracy': 0.38974358974358975},\n",
       "  'Arabic Art': {'Accuracy': 0.38974358974358975},\n",
       "  'United Arab Emirates': {'Accuracy': 0.29411764705882354},\n",
       "  'Islam branches and schools': {'Accuracy': 0.41714285714285715},\n",
       "  'InfluenceFromByzantium': {'Accuracy': 0.7172413793103448},\n",
       "  'Arab Empire': {'Accuracy': 0.30943396226415093},\n",
       "  'Arabic Food': {'Accuracy': 0.46153846153846156},\n",
       "  'Mauritania': {'Accuracy': 0.4222222222222222},\n",
       "  'entertainment': {'Accuracy': 0.5016949152542373},\n",
       "  'communication': {'Accuracy': 0.5274725274725275},\n",
       "  'Palestine': {'Accuracy': 0.43529411764705883},\n",
       "  'Bahrain': {'Accuracy': 0.35555555555555557},\n",
       "  'Somalia': {'Accuracy': 0.35555555555555557},\n",
       "  'Iraq': {'Accuracy': 0.5058823529411764},\n",
       "  'Arabic Clothing': {'Accuracy': 0.5128205128205128},\n",
       "  'Arabic Architecture': {'Accuracy': 0.46153846153846156},\n",
       "  'Morocco': {'Accuracy': 0.2222222222222222},\n",
       "  'average': {'Accuracy': 0.44233102914943495},\n",
       "  'overall': {'Accuracy': 0.46475315729047073}},\n",
       " 'middle': {'talks': {'Accuracy': 0.0},\n",
       "  'traditional festival': {'Accuracy': 0.7142857142857143},\n",
       "  'life': {'Accuracy': 0.6363636363636364},\n",
       "  'specialExpression': {'Accuracy': 0.68},\n",
       "  'Islam': {'Accuracy': 1.0},\n",
       "  'traveling': {'Accuracy': 0.6666666666666666},\n",
       "  'trade and bussness': {'Accuracy': 0.8},\n",
       "  'average': {'Accuracy': 0.6424737167594311},\n",
       "  'overall': {'Accuracy': 0.68}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.load(open(os.path.join('benchmark_eval/results/ArabicCulture/bloomz-ace-v5.0/zero_shot/metrics.json')))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01051f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'easy': {'Arabic Funeral': {'Accuracy': 0.7157894736842105},\n",
       "  'Sudan': {'Accuracy': 0.8444444444444444},\n",
       "  'Arabic Physics and Chemistry': {'Accuracy': 0.9179487179487179},\n",
       "  'Algeria': {'Accuracy': 0.764102564102564},\n",
       "  'InfluenceFromAncientEgypt': {'Accuracy': 0.8358974358974359},\n",
       "  'Arabic Ceremony': {'Accuracy': 0.6918918918918919},\n",
       "  'Arabic Astronomy': {'Accuracy': 0.5282051282051282},\n",
       "  'Arabic Calligraphy': {'Accuracy': 0.7137254901960784},\n",
       "  'daily life': {'Accuracy': 0.7151335311572701},\n",
       "  'Saudi Arabia': {'Accuracy': 0.8615384615384616},\n",
       "  'Arabic Language Origin': {'Accuracy': 0.7263157894736842},\n",
       "  'Arabic Ornament': {'Accuracy': 0.7794871794871795},\n",
       "  'Islamic law system': {'Accuracy': 0.8},\n",
       "  'Kuwait': {'Accuracy': 0.5777777777777777},\n",
       "  'InfluenceFromChina': {'Accuracy': 0.717948717948718},\n",
       "  'Arabic Literature': {'Accuracy': 0.8068965517241379},\n",
       "  'computer and phone': {'Accuracy': 0.6847457627118644},\n",
       "  'Tunisia': {'Accuracy': 0.7555555555555555},\n",
       "  'Arabic Geography': {'Accuracy': 0.7310344827586207},\n",
       "  'Arabic Music': {'Accuracy': 0.6762589928057554},\n",
       "  'Arabic Medicine': {'Accuracy': 0.8827586206896552},\n",
       "  'Arabic Philosophy': {'Accuracy': 0.5655172413793104},\n",
       "  'Yemen': {'Accuracy': 0.6},\n",
       "  'Jordan': {'Accuracy': 0.7555555555555555},\n",
       "  'Mesopotamia civilization': {'Accuracy': 0.7225806451612903},\n",
       "  'Islam Education': {'Accuracy': 0.8512820512820513},\n",
       "  'Arabic Wedding': {'Accuracy': 0.8769230769230769},\n",
       "  'InfluenceFromRome': {'Accuracy': 0.676923076923077},\n",
       "  'Egypt modern': {'Accuracy': 0.8421052631578947},\n",
       "  'Ancient Egypt': {'Accuracy': 0.8285714285714286},\n",
       "  'Comoros': {'Accuracy': 0.7111111111111111},\n",
       "  'InfluenceFromGreece': {'Accuracy': 0.7743589743589744},\n",
       "  'Qatar': {'Accuracy': 0.8222222222222222},\n",
       "  'InfluenceFromPersia': {'Accuracy': 0.9142857142857143},\n",
       "  'Lebanon': {'Accuracy': 0.6222222222222222},\n",
       "  'Arabic Math': {'Accuracy': 0.7487179487179487},\n",
       "  'Arabic History': {'Accuracy': 0.5846153846153846},\n",
       "  'InfluenceFromIslam': {'Accuracy': 0.9379310344827586},\n",
       "  'Libya': {'Accuracy': 0.8444444444444444},\n",
       "  'Syria': {'Accuracy': 0.8},\n",
       "  'Oman': {'Accuracy': 0.7333333333333333},\n",
       "  'Arabic Culture': {'Accuracy': 0.6512820512820513},\n",
       "  'Arabic Art': {'Accuracy': 0.7487179487179487},\n",
       "  'United Arab Emirates': {'Accuracy': 0.6235294117647059},\n",
       "  'Islam branches and schools': {'Accuracy': 0.7371428571428571},\n",
       "  'InfluenceFromByzantium': {'Accuracy': 0.8},\n",
       "  'Arab Empire': {'Accuracy': 0.49433962264150944},\n",
       "  'Arabic Food': {'Accuracy': 0.6820512820512821},\n",
       "  'Mauritania': {'Accuracy': 0.8},\n",
       "  'entertainment': {'Accuracy': 0.559322033898305},\n",
       "  'communication': {'Accuracy': 0.4945054945054945},\n",
       "  'Palestine': {'Accuracy': 0.8470588235294118},\n",
       "  'Bahrain': {'Accuracy': 0.6888888888888889},\n",
       "  'Somalia': {'Accuracy': 0.7777777777777778},\n",
       "  'Iraq': {'Accuracy': 0.7647058823529411},\n",
       "  'Arabic Clothing': {'Accuracy': 0.49230769230769234},\n",
       "  'Arabic Architecture': {'Accuracy': 0.7025641025641025},\n",
       "  'Morocco': {'Accuracy': 0.8444444444444444},\n",
       "  'average': {'Accuracy': 0.7353240622864889},\n",
       "  'overall': {'Accuracy': 0.7219288174512055}},\n",
       " 'middle': {'talks': {'Accuracy': 0.0},\n",
       "  'traditional festival': {'Accuracy': 0.0},\n",
       "  'life': {'Accuracy': 0.0},\n",
       "  'specialExpression': {'Accuracy': 0.0},\n",
       "  'Islam': {'Accuracy': 0.0},\n",
       "  'traveling': {'Accuracy': 0.0},\n",
       "  'trade and bussness': {'Accuracy': 0.0},\n",
       "  'average': {'Accuracy': 0.0},\n",
       "  'overall': {'Accuracy': 0.0}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.load(open(os.path.join('benchmark_eval/results/ArabicCulture/llama-raw-pretrained-sencondround-ckpt0-430000/few_shot/metrics.json')))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a4323c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5494abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080bbb01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
